---
title: "Assignment_1"
author: "Ida Dencker"
date: "2025-02-11"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
pacman::p_load(tibble, tidyverse)
```


# STRATEGY 1: ASSYMETRICAL WSLS

```{r}
#(Asymmetrical WSLS) vs Random with one rate of 0.7

WSLSAgent_f <- function(prevChoice, recentChoice, prevfeedback, recentfeedback) {
  if (prevfeedback == 1 & recentfeedback == 1 & prevChoice == recentChoice) {
    choice <- 1 - prevChoice  # Switch if won twice in a row with same hand
  } else if (prevfeedback == 1) {
    choice <- prevChoice  # Stay if won last round
  } else {
    choice <- 1 - prevChoice  # Switch if lost last round
  }
  return(choice)
}

RandomAgent_f <- function(input, rate = 0.7) {
  # Input validation
  if (!is.numeric(rate) || rate < 0 || rate > 1) {
    stop("Rate must be a probability between 0 and 1")
  }
  
  n <- length(input)
  choice <- rbinom(n, 1, rate)
  return(choice)
}


trials = 120
agents = 100

# WSLS vs agents with varying rates
for (agent in seq(agents)) {
  Self <- rep(NA, trials)
  Other <- rep(NA, trials)
  
  Self[1] <- RandomAgent_f(1, 0.5)  # 1st trial choice (random)
  Other <- RandomAgent_f(seq(trials), rate=0.7)  # Other's choices for all trials

  # Get first feedback
  prevfeedback <- as.numeric(Self[1] == Other[1])
  #Self[1] == Other[1] produces a boolean value: as numeric will take that and turn it into a 1 if true 
  
  # Assign Self[2] based on first feedback
  if (prevfeedback == 1) {
    Self[2] <- Self[1]  # Stay with previous choice
  } else {
    Self[2] <- 1 - Self[1]  # Switch choice
  }

  # Get second feedback
  recentfeedback <- as.numeric(Self[2] == Other[2])

  # Start the loop from the third trial
  for (i in 3:trials) {
    recentfeedback <- prevfeedback  # Shift feedback history i.e overwrite feedbacks
    prevfeedback <- as.numeric(Self[i - 1] == Other[i - 1])  # New feedback
  
    recentChoice <- Self[i - 2]  # Choice from two rounds ago
    prevChoice <- Self[i - 1]  # Last round's choice
  
    Self[i] <- WSLSAgent_f(prevChoice, recentChoice, prevfeedback, recentfeedback)
  } #make the current choise using the function

    temp <- tibble(Self, Other, trial = seq(trials), prevfeedback = as.numeric(Self == Other), agent)
  
  if (agent == 1) {
    df <- temp
  } else {
    df <- bind_rows(df, temp)
  }
}


```



```{r}
#(Asymmetrical WSLS) vs Random with diff rates (not reported)

WSLSAgent_f <- function(prevChoice, recentChoice, prevfeedback, recentfeedback) {
  if (prevfeedback == 1 & recentfeedback == 1 & prevChoice == recentChoice) {
    choice <- 1 - prevChoice  # Switch if won twice in a row with same hand
  } else if (prevfeedback == 1) {
    choice <- prevChoice  # Stay if won last round
  } else {
    choice <- 1 - prevChoice  # Switch if lost last round
  }
  return(choice)
}

RandomAgent_f <- function(input, rate) {
  # Input validation
  if (!is.numeric(rate) || rate < 0 || rate > 1) {
    stop("Rate must be a probability between 0 and 1")
  }
  
  n <- length(input)
  choice <- rbinom(n, 1, rate)
  return(choice)
}


trials = 120
agents = 100

# WSLS vs agents with varying rates
for (rate in seq(from = 0.5, to = 1, by = 0.05)) {
  for (agent in seq(agents)) {
    Self <- rep(NA, trials)
    Other <- rep(NA, trials)
    
    Self[1] <- RandomAgent_f(1, 0.5)  # 1st trial choice (random)
    Other <- RandomAgent_f(seq(trials), rate)  # Other's choices for all trials

    # Get first feedback
    prevfeedback <- as.numeric(Self[1] == Other[1])
    #Self[1] == Other[1] produces a boolean value: as numeric will take that and turn it into a 1 if true 
    
    
    # Assign Self[2] based on first feedback
    if (prevfeedback == 1) {
      Self[2] <- Self[1]  # Stay with previous choice
    } else {
      Self[2] <- 1 - Self[1]  # Switch choice
    }

    # Get second feedback
    recentfeedback <- as.numeric(Self[2] == Other[2])

    # Start the loop from the third trial
    for (i in 3:trials) {
      recentfeedback <- prevfeedback  # Shift feedback history i.e overwrite feedbacks
      prevfeedback <- as.numeric(Self[i - 1] == Other[i - 1])  # New feedback
    
      recentChoice <- Self[i - 2]  # Choice from two rounds ago
      prevChoice <- Self[i - 1]  # Last round's choice
    
      Self[i] <- WSLSAgent_f(prevChoice, recentChoice, prevfeedback, recentfeedback)
    } #make the current choise using the function

    temp_3 <- tibble(Self, Other, trial = seq(trials), prevfeedback = as.numeric(Self == Other), agent, rate)
    
    if (agent == 1 & rate == 0.5) {
      df_3 <- temp_3
    } else {
      df_3 <- bind_rows(df_3, temp_3)
    }

      
  }
   
}

```



```{r}
#(Asymmetrical WSLS) vs Traditional WSLS 

WSLSAgent_f <- function(prevChoice, recentChoice, prevfeedback, recentfeedback) {
  if (prevfeedback == 1 & recentfeedback == 1 & prevChoice == recentChoice) {
    choice <- 1 - prevChoice  # Switch if won twice in a row with same hand
  } else if (prevfeedback == 1) {
    choice <- prevChoice  # Stay if won last round
  } else {
    choice <- 1 - prevChoice  # Switch if lost last round
  }
  return(choice)
}


coreWSLSAgent_f <- function(prevChoice, prevfeedback) {
  # Core WSLS logic
  choice <- if (prevfeedback == 0) { # a 0 for this agent will mean a win
    prevChoice  # Stay with previous choice if won
  } else {
    1 - prevChoice  # Switch to opposite choice if lost
  }

  return(choice)
}

RandomAgent_f <- function(input, rate) {
  # Input validation
  if (!is.numeric(rate) || rate < 0 || rate > 1) {
    stop("Rate must be a probability between 0 and 1")
  }
  
  n <- length(input)
  choice <- rbinom(n, 1, rate)
  return(choice)
}


trials = 120
agents = 100

# WSLS assymetric vs WSLS
for (agent in seq(agents)) {
  Self <- rep(NA, trials)
  Other <- rep(NA, trials)
  
  Self[1] <- RandomAgent_f(1, 0.5)  # 1st trial choice (random)
  Other[1] <- RandomAgent_f(1, 0.5)
  
  # Get first feedback
  prevfeedback <- as.numeric(Self[1] == Other[1])
  #Self[1] == Other[1] produces a boolean value: as numeric will take that and turn it into a 1 if true 

  
  # Assign Self[2] based on first feedback
  if (prevfeedback == 1) {
    Self[2] <- Self[1]  # Stay with previous choice
  } else {
    Self[2] <- 1 - Self[1]  # Switch choice
  }
  
  if (prevfeedback == 0) {
    Other[2] <- Other[1]  # Stay with previous choice
  } else {
    Other[2] <- 1 - Other[1]  # Switch choice
  }
  

  # Get second feedback
  recentfeedback <- as.numeric(Self[2] == Other[2])

  # Start the loop from the third trial
  for (i in 3:trials) {
    recentfeedback <- prevfeedback  # Shift feedback history i.e overwrite feedbacks
    prevfeedback <- as.numeric(Self[i - 1] == Other[i - 1])  # New feedback
  
    recentChoice <- Self[i - 2]  # Choice from two rounds ago
    prevChoice <- Self[i - 1]  # Last round's choice
  
    Self[i] <- WSLSAgent_f(prevChoice, recentChoice, prevfeedback, recentfeedback) 
    Other[i] <- coreWSLSAgent_f(Other[i - 1], prevfeedback)
  } 

    temp_2 <- tibble(Self, Other, trial = seq(trials), prevfeedback = as.numeric(Self == Other), agent)
  
  if (agent == 1) {
    df_2 <- temp_2 #create df for first agent
  } else {
    df_2 <- bind_rows(df_2, temp_2) #bind from there on
  }
}
   

```

## Plotting strategy 1

```{r}
# Plot 1
ggplot(df) + theme_classic() +
  geom_line(color = "red", aes(trial, Self)) +
  geom_line(color = "blue", aes(trial, Other)) +
  labs(
    title = "Asymmetrical WSLS Agent (red) vs Biased Random Opponent (0.7 rate) (blue)",
    x = "Trial Number",
    y = "Choice (0/1)",
    color = "Agent Type"
  )
```

```{r}
# Plot 2
ggplot(df_2) + theme_classic() +
  geom_line(color = "red", aes(trial, Self)) +
  geom_line(color = "blue", aes(trial, Other)) +
  labs(
    title = "Asymmetrical WSLS Agent (red) vs Traditional WSLS Agent Opponent (blue)",
    x = "Trial Number",
    y = "Choice (0/1)",
    color = "Agent Type"
  )
```


```{r}
# Plot 3
ggplot(df) + theme_classic() +
  geom_line(color = "red", aes(trial, prevfeedback)) +
  geom_line(color = "blue", aes(trial, 1 - prevfeedback)) +
  labs(
    title = "Asymmetrical WSLS Agent (red) vs Biased Random Opponent (0.7 rate) (blue)",
    x = "Trial Number",
    y = "Feedback received (0/1)",
    color = "Agent Type"
  )
```
```{r}
# Plot 4
ggplot(df_2) + theme_classic() +
  geom_line(color = "red", aes(trial, prevfeedback)) +
  geom_line(color = "blue", aes(trial, 1 - prevfeedback)) +
  labs(
    title = "Asymmetrical WSLS Agent (red) vs Traditional WSLS Agent Opponent (blue)",
    x = "Trial Number",
    y = "Feedback received (0/1)",
    color = "Agent Type"
  )
```


```{r}
# Plot 5
df$cumulativerateSelf <- cumsum(df$prevfeedback) / seq_along(df$prevfeedback)
df$cumulativerateOther <- cumsum(1 - df$prevfeedback) / seq_along(df$prevfeedback)

ggplot(df) + theme_classic() +
  geom_line(color = "red", aes(trial, cumulativerateSelf)) +
  geom_line(color = "blue", aes(trial, cumulativerateOther))  +
  labs(
    title = "Asymmetrical WSLS Agent (red) vs Biased Random Opponent (0.7 rate) (blue)",
    x = "Trial Number",
    y = "Cumulative success",
    color = "Agent Type"
  )
```
```{r}
# Plot 6
df_2$cumulativerateSelf <- cumsum(df_2$prevfeedback) / seq_along(df_2$prevfeedback)
df_2$cumulativerateOther <- cumsum(1 - df_2$prevfeedback) / seq_along(df_2$prevfeedback)

ggplot(df_2) + theme_classic() +
  geom_line(color = "red", aes(trial, cumulativerateSelf)) +
  geom_line(color = "blue", aes(trial, cumulativerateOther))  +
  labs(
    title = "Asymmetrical WSLS Agent (red) vs Traditional WSLS Agent Opponent (blue)",
    x = "Trial Number",
    y = "Cumulative success",
    color = "Agent Type"
  )
```


# STRATEGY 2: MEMORY MODEL

```{r}

# Our random agent (same as Riccardo)
RandomAgent_f <- function(input, rate = 0.5) {
  # Input validation
  if (!is.numeric(rate) || rate < 0 || rate > 1) {
    stop("Rate must be a probability between 0 and 1")
  }
  
  n <- length(input)
  choice <- rbinom(n, 1, rate)
  return(choice)
}

# Our memory agent without probability (not reported)
# Define function
MemoryAgent_noprob <- function(prevOther) {
  
  # Input validation
  if (!is.numeric(prevOther) || !all(prevOther %in% c(0, 1))) {
    stop("Previous hand must be 0 or 1")
  }
  if (length(prevOther) != 5) {
    stop("There must be 5 previous rounds")
  }
  
  # Count occurrences of left (0) and right (1) hand
  num_left <- sum(prevOther == 0)
  num_right <- sum(prevOther == 1)
  
  # Define decision rule based on memory of the previous 5 trials
  choice <- if (num_left > num_right) {
    1 # if more occurrences of left, choose right
  } else {
    0 # if more occurrences of right, choose left 
  }
  
  return(choice)
}


# Our memory agent with probability 
# Define function
MemoryAgent_f <- function(prevOther) {
  
  # Input validation
  if (!is.numeric(prevOther) || !all(prevOther %in% c(0, 1))) {
    stop("Previous hand must be 0 or 1")
  }
  if (length(prevOther) != 5) {
    stop("There must be 5 previous rounds")
  }
  
  # Count occurrences of left (0) and right (1) hand
  num_left <- sum(prevOther == 0)
  num_right <- sum(prevOther == 1)
  
  # Define decision rule based on memory of the previous 5 trials
  choice <- if (num_left > num_right) {
    rbinom(1, 1, 0.7)
  } else {
    #sample(c(0,1), 0.3) # if fewer occurrences of left, higher probability of left (0)
    rbinom(1, 1, 0.3)
  }
  
  return(choice)
}


# Comparing the memory agent to the random agent
# Set parameters
trials = 120
agents = 100

# Memory agents vs random agents with varying rates
#for (rate in seq(from = 0.5, to = 1, by = 0.05)) {
for (agent in seq(agents)) {
  Self <- rep(NA, trials)
  Other <- rep(NA, trials)
  
  # Pre-define the first 5 trials 
  Self[1:5] <- RandomAgent_f(1:5, rate = 0.5)
  #Other[1:5] <- RandomAgent_f(1:5, rate = 0.5) 
  Other <- RandomAgent_f(seq(trials), rate = 0.5)

  # Start the loop after 5 trials
  for (i in 6:trials) {  
    #Other <- RandomAgent_f(seq(trials), rate = 0.5)
    prevOther <- Other[(i-5):(i-1)] # load the five previous trials
    Self[i] <- MemoryAgent_f(prevOther)
  }
  
  temp_4 <- tibble(Self, Other, trial = seq(trials), agent)
  
 if (agent == 1) {
   df_new <- temp_4
} else {
   df_new <- bind_rows(df_new, temp_4)  
}
}
```


## Plotting strategy 2

```{r}
# Plotting the choices
ggplot(df_new, aes(trial, Self)) + 
  theme_classic() + 
  geom_line(color="red") + 
  geom_line(color="blue",aes(trial,Other)) +
  ggtitle("Memory agent vs. random agent: Choices across trials")

# Plotting the feedback
# Calculate feedback
df_new <- df_new %>% 
  mutate(Feedback = case_when(
    Self == Other ~ "1",
    Self != Other ~ "0",
    TRUE ~ NA_character_
  ))

# Transform variable
df_new$Feedback <- as.integer(df_new$Feedback)

# Calculating the cumulative sum 
df_new$cumulativerateSelf <- cumsum(df_new$Feedback) / seq_along(df_new$Feedback)
df_new$cumulativerateOther <- cumsum(1 - df_new$Feedback) / seq_along(df_new$Feedback)

# Plotting
ggplot(df_new) + theme_classic() +
  geom_line(color = "red", aes(trial, cumulativerateSelf)) +
  geom_line(color = "blue", aes(trial, cumulativerateOther)) +
  ggtitle("Memory agent vs. random agent: Cumulative feedback across trials")
```

